# 10.3 SLAM技术概述

小伙伴们好，上一节我们搭建好了Gazebo中的仿真环境，本节课我们一起来了解一下SLAM技术。

第一节中我们知道，要解决机器人自主导航问题就需要有感知（建图和定位）参与，通过感知输出机器人当前环境的地图信息和位置。而本节要讲的SLAM就是解决地图和定位问题的。

## 1. SLAM是什么

SLAM是同步定位与地图构建(Simultaneous Localization And Mapping)的缩写。

先通过一个视频直观了解一下

<iframe height="400" width="600" src="//player.bilibili.com/player.html?aid=724624445&bvid=BV1tS4y1S7qE&cid=544765528&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="false"> </iframe>

视频中随着机器人的移动，机器人的传感器获取到了环境信息，然后完成对博物馆地图的构建。

> 有小伙伴可能会问，只看到建图没看到定位呀。细心观察可以发现建图的过程中，其实一直都在计算机器人的位置。

## 2. SLAM如何解决建图定位问题

机器人通过自身传感器数据处理进行位置估计，同时通过不断移动完成对整个未知环境的地图构建。这就是SLAM解决的问题。

那又是如何解决的呢？SLAM实现的方案很多，但是几个比较关键的技术如下：

1. 传感器感知
    通过各类传感器实现对环境的感知，比如通过激光雷达获取环境的深度信息。同时可以通过传感器融合来提高位置估计的精度，比如融合轮式里程计、IMU、雷达、深度相机数据等。

2. 视觉/激光里程计
    基本原理是通过前后数据之间对比得出机器人位置的变化。

3. 回环检测
    判断机器人是否到达之前到过的位置，可以解决位置估计误差问题，建图时可以纠正地图误差。


经典视觉SLAM结构

![经典视觉SLAM结构](10.3SLAM技术概述/imgs/image-20220421152216184.png)

## 3.SLAM算法分类

从算法的对数据的处理方式上看，目前常用的SLAM开源算法可以分为两类

1.基于滤波，比如扩展卡尔曼滤波（EKF: Extended Kalman Filter）、粒子滤波(PF: Particle Filter)等。

ROS中的gmapping、hector_slam算法都是基于滤波实现的。

2.基于图优化，先通过传感器进行构图，然后对图进行优化。

目前比较主流的是图优化的方法，Cartographer就是基于图优化实现的。图优化相对于滤波，不用实时的进行计算，效率更高，消耗的资源更少，所以在实际场景中使用的更多。

## 4.SLAM开源库

### 4.1. Cartographer

github地址：https://github.com/cartographer-project/cartographer

Cartographer是一个可跨多个平台和传感器配置以2D和3D形式提供实时同时定位和建图（SLAM）的系统。

### 4.2. ORB_SLAM2(纯视觉)

github地址：https://github.com/raulmur/ORB_SLAM2

ORB-SLAM2是用于单目，双目和RGB-D相机的实时SLAM库，用于计算相机轨迹和稀疏3D重建

### 4.3 VINS

github地址：https://github.com/HKUST-Aerial-Robotics/VINS-Mono

VINS-Mono是单目视觉惯性系统的实时SLAM框架。它使用基于优化的滑动窗口配方来提供高精度的视觉惯性测距。

## 5.总结

本节课我们简单介绍了下感知部分的技术担当SLAM，并对常用的开源库进行介绍，下一节我们就对其中的Cartograpger开源库进行介绍和安装。



参考文章：

- https://blog.csdn.net/heyijia0327/article/details/47686523

--------------

技术交流&&问题求助：

- **微信公众号及交流群：鱼香ROS**
- **小鱼微信：AiIotRobot**
- **QQ交流群：139707339**

- 版权保护：已加入“维权骑士”（rightknights.com）的版权保护计划
